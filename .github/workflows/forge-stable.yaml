# Continuously run stable forge tests against the latest main branch.
name: Continuous Forge Tests - Stable

# We have various Forge Stable tests here, that test out different situations and workloads.
#
# Dashboard showing historical results: https://grafana.aptoslabs.com/d/bdnt45ggsg000f/forge-stable-performance?orgId=1

# Tests are named based on how they are set up, some of the common flavors are:
# * "realistic-env" - tests with "realistic-env" in their name try to have network and hardware environemnt
#   be more realisistic. They use "wrap_with_realistic_env", which sets:
#   * MultiRegionNetworkEmulationTest which splits nodes into 4 "regions", which have different
#     x-region and in-region latencies and reliability rates
#   * CpuChaosTest which tries to make nodes have heterogenous hardware, by loading a few cores fully 
#     on a few nodes. But this is not too helpful, as block execution time variance is minimal 
#     (as we generally have a few idle cores, and real variance mostly comes from variance in cpu speed instead)
# * sweep - means running a multiple tests within a single test, by having everything the same, except for one 
#   thing - i.e. the thing we sweep over. There are two main dimensions we "sweep" over:
#   * load sweep - this generally uses const tps workload, and varies the load across the tests (i.e. 10 vs 100 vs 1000 TPS) 
#   * workload sweep - this varies the transaction type being submitted, trying to test out how the system behaves
#     when different part of the system are stressed (i.e. low vs high output sizes, good vs bad gas calibration, parallel vs sequential, etc)
# * graceful - tests where we are overloading the system - i.e. submitting more transactions than we expect system to handle,
#   and seeing how it behaves. overall e2e latency is then high, but we can test that only validator -> block proposal has increased.
#   additionally, we generally add a small TPS high-fee traffic in these tests, to confirm it is unaffected by the high load.
# * changing-working-quorum - tests where we intentionally make nodes unreachable (cut their network), and bring them back,
#   and go to cut network on next set of nodes - requiring state-sync to catch up, consensus to work with different set of 
#   nodes being required to form consensus. During each iteration, we test that enough progress was made.
#
# Main success criteria used across the tests are:
# * throughput and expiration/rejection rate 
# * latency (avg / p50 / p90 / p99 )
# * latency breakdown across the components - currently within a validator alone:
#   batch->pos->proposal->ordered->committed
#   TODO: we should add other stages - before batch and after committed to success criteria, to be able to track them better
# * chain progress - checking longest pause between the blocks (both in num failed runs, and in absolute time) across the run
# * catchup - that all nodes can go over the same version at the end of the load (i.e. catching if any individual validator got stuck)
# * no restarts - fails if any node has restarted within the test
# * system metrics - checks for CPU and RAM utilization during the test
#
#
# You can find more details about the individual tests below.

permissions:
  issues: write
  pull-requests: write
  contents: read
  id-token: write
  actions: write #required for workflow cancellation via check-aptos-core

concurrency:
  group: forge-stable-${{ github.ref_name }}
  cancel-in-progress: true

on:
  # Allow triggering manually
  workflow_dispatch:
    inputs:
      IMAGE_TAG:
        required: false
        type: string
        description: The docker image tag to test. This may be a git SHA1, or a tag like "<branch>_<git SHA1>". If not specified, Forge will find the latest build based on the git history (starting from GIT_SHA input)
      GIT_SHA:
        required: false
        type: string
        description: The git SHA1 to checkout. This affects the Forge test runner that is used. If not specified, the latest main will be used
  # NOTE: to support testing different branches on different schedules, you need to specify the cron schedule in the 'determine-test-branch' step as well below
  # Reference: https://docs.github.com/en/actions/using-workflows/events-that-trigger-workflows#schedule
  schedule:
    - cron: "0 22 * * 0,2,4" # The main branch cadence. This runs every Sun,Tues,Thurs
  pull_request:
    paths:
      - ".github/workflows/forge-stable.yaml"
      - "testsuite/find_latest_image.py"

env:
  AWS_ACCOUNT_NUM: ${{ secrets.ENV_ECR_AWS_ACCOUNT_NUM }}
  AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
  AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
  IMAGE_TAG: ${{ inputs.IMAGE_TAG }} # this is only used for workflow_dispatch, otherwise defaults to empty
  AWS_REGION: us-west-2

jobs:
  # This job determines the image tag and branch to test, and passes them to the other jobs
  # NOTE: this may be better as a separate workflow as the logic is quite complex but generalizable
  determine-test-metadata:
    runs-on: ubuntu-latest
    outputs:
      IMAGE_TAG: ${{ steps.get-docker-image-tag.outputs.IMAGE_TAG }}
      IMAGE_TAG_FOR_COMPAT_TEST: ${{ steps.get-last-released-image-tag-for-compat-test.outputs.IMAGE_TAG }}
      BRANCH: ${{ steps.determine-test-branch.outputs.BRANCH }}
      BRANCH_HASH: ${{ steps.hash-branch.outputs.BRANCH_HASH }}
    steps:
      - uses: actions/checkout@v4

      - name: Determine branch based on cadence
        id: determine-test-branch
        # NOTE: the schedule cron MUST match the one in the 'on.schedule.cron' section above
        run: |
          if [[ "${{ github.event_name }}" == "schedule" ]]; then
            if [[ "${{ github.event.schedule }}" == "0 22 * * 0,2,4" ]]; then
              echo "Branch: main"
              echo "BRANCH=main" >> $GITHUB_OUTPUT
            else
              echo "Unknown schedule: ${{ github.event.schedule }}"
              exit 1
            fi
          elif [[ "${{ github.event_name }}" == "push" ]]; then
              echo "Branch: ${{ github.ref_name }}"
              echo "BRANCH=${{ github.ref_name }}" >> $GITHUB_OUTPUT
          else
            echo "Using GIT_SHA"
            # on workflow_dispatch, this will simply use the inputs.GIT_SHA given (or the default)
            # on pull_request, this will default to null and the following "checkout" step will use the PR's base branch
            echo "BRANCH=${{ inputs.GIT_SHA }}" >> $GITHUB_OUTPUT
          fi

      # Use the branch hash instead of the full branch name to stay under kubernetes namespace length limit
      - name: Hash the branch
        id: hash-branch
        run: |
          # If BRANCH is empty, default to "main"
          if [ -z "${{ steps.determine-test-branch.outputs.BRANCH }}" ]; then
            BRANCH="main"
          else
            BRANCH="${{ steps.determine-test-branch.outputs.BRANCH }}"
          fi

          # Hashing the branch name
          echo "BRANCH_HASH=$(echo -n "$BRANCH" | sha256sum | cut -c1-10)" >> $GITHUB_OUTPUT

      - uses: aptos-labs/aptos-core/.github/actions/check-aptos-core@main
        with:
          cancel-workflow: ${{ github.event_name == 'schedule' }} # Cancel the workflow if it is scheduled on a fork

      # actions/get-latest-docker-image-tag requires docker utilities and having authenticated to internal docker image registries
      - uses: aptos-labs/aptos-core/.github/actions/docker-setup@main
        id: docker-setup
        with:
          GCP_WORKLOAD_IDENTITY_PROVIDER: ${{ secrets.GCP_WORKLOAD_IDENTITY_PROVIDER }}
          GCP_SERVICE_ACCOUNT_EMAIL: ${{ secrets.GCP_SERVICE_ACCOUNT_EMAIL }}
          EXPORT_GCP_PROJECT_VARIABLES: "false"
          AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          AWS_DOCKER_ARTIFACT_REPO: ${{ secrets.AWS_DOCKER_ARTIFACT_REPO }}
          GIT_CREDENTIALS: ${{ secrets.GIT_CREDENTIALS }}

      - uses: aptos-labs/aptos-core/.github/actions/get-latest-docker-image-tag@main
        id: get-docker-image-tag
        with:
          branch: ${{ steps.determine-test-branch.outputs.BRANCH }}
          variants: "failpoints performance"

      - uses: ./.github/actions/determine-or-use-target-branch-and-get-last-released-image
        id: get-last-released-image-tag-for-compat-test
        with:
          base-branch: ${{ steps.determine-test-branch.outputs.BRANCH }}
          variants: "failpoints performance"

      - name: Write summary
        run: |
          IMAGE_TAG=${{ steps.get-docker-image-tag.outputs.IMAGE_TAG }}
          IMAGE_TAG_FOR_COMPAT_TEST=${{ steps.get-last-released-image-tag-for-compat-test.outputs.IMAGE_TAG }}
          TARGET_BRANCH_TO_FETCH_IMAGE_FOR_COMPAT_TEST=${{ steps.get-last-released-image-tag-for-compat-test.outputs.TARGET_BRANCH }}
          BRANCH=${{ steps.determine-test-branch.outputs.BRANCH }}
          if [ -n "${BRANCH}" ]; then
            echo "BRANCH: [${BRANCH}](https://github.com/${{ github.repository }}/tree/${BRANCH})" >> $GITHUB_STEP_SUMMARY
          fi
          echo "IMAGE_TAG: [${IMAGE_TAG}](https://github.com/${{ github.repository }}/commit/${IMAGE_TAG})" >> $GITHUB_STEP_SUMMARY

  ### Real-world-network tests.
  # Run forge framework upgradability test. This is a PR required job.
  run-forge-framework-upgrade-test:
    if: ${{ github.event_name != 'pull_request' }}
    needs:
      - determine-test-metadata
    uses: aptos-labs/aptos-core/.github/workflows/workflow-run-forge.yaml@main
    secrets: inherit
    with:
      IMAGE_TAG: ${{ needs.determine-test-metadata.outputs.IMAGE_TAG_FOR_COMPAT_TEST }}
      FORGE_NAMESPACE: forge-framework-upgrade-${{ needs.determine-test-metadata.outputs.BRANCH_HASH }}
      FORGE_RUNNER_DURATION_SECS: 7200 # Run for 2 hours
      FORGE_TEST_SUITE: framework_upgrade
      POST_TO_SLACK: true

  # Test varies the load, i.e. sending 10, 100, 1000, 5000, etc TPS, and then measuring 
  # onchain TPS, expired rate, as well as p50/p90/p99 latency, among other things,
  # testing that we don't degrade performance both for low, mid and high loads. 
  run-forge-realistic-env-load-sweep:
    if: ${{ github.event_name != 'pull_request' && always() }}
    needs: [determine-test-metadata, run-forge-framework-upgrade-test] # Only run after the previous job completes
    uses: aptos-labs/aptos-core/.github/workflows/workflow-run-forge.yaml@main
    secrets: inherit
    with:
      IMAGE_TAG: ${{ needs.determine-test-metadata.outputs.IMAGE_TAG }}
      FORGE_NAMESPACE: forge-realistic-env-load-sweep-${{ needs.determine-test-metadata.outputs.BRANCH_HASH }}
      FORGE_RUNNER_DURATION_SECS: 1800 # Run for 30 minutes (6 tests, each for 300 seconds)
      FORGE_TEST_SUITE: realistic_env_load_sweep
      POST_TO_SLACK: true

  # Test varies the workload, across some basic workloads (i.e. some cheap, some expensive), and checks that 
  # throughput and performance across different stages
  run-forge-realistic-env-workload-sweep:
    if: ${{ github.event_name != 'pull_request' && always() }}
    needs: [determine-test-metadata, run-forge-realistic-env-load-sweep] # Only run after the previous job completes
    uses: aptos-labs/aptos-core/.github/workflows/workflow-run-forge.yaml@main
    secrets: inherit
    with:
      IMAGE_TAG: ${{ needs.determine-test-metadata.outputs.IMAGE_TAG }}
      FORGE_NAMESPACE: forge-realistic-env-workload-sweep-${{ needs.determine-test-metadata.outputs.BRANCH_HASH }}
      FORGE_RUNNER_DURATION_SECS: 2000 # Run for 33 minutes (5 tests, each for 400 seconds)
      FORGE_TEST_SUITE: realistic_env_workload_sweep
      POST_TO_SLACK: true

  # Test sends ConstTps workload above what the system can handle, while additionally sending non-small high-fee traffic (1000 TPS),
  # and measures overall system performance.
  run-forge-realistic-env-graceful-overload:
    if: ${{ github.event_name != 'pull_request' && always() }}
    needs: [determine-test-metadata, run-forge-realistic-env-workload-sweep] # Only run after the previous job completes
    uses: aptos-labs/aptos-core/.github/workflows/workflow-run-forge.yaml@main
    secrets: inherit
    with:
      IMAGE_TAG: ${{ needs.determine-test-metadata.outputs.IMAGE_TAG }}
      FORGE_NAMESPACE: forge-realistic-env-graceful-overload-${{ needs.determine-test-metadata.outputs.BRANCH_HASH }}
      FORGE_RUNNER_DURATION_SECS: 1200 # Run for 20 minutes
      FORGE_TEST_SUITE: realistic_env_graceful_overload
      POST_TO_SLACK: true

  # Test varies the workload (opposite ends of gas calibration, high and low output sizes, sequential / parallel, etc), 
  # and sends ConstTPS for each above what the system can handle, while sending low TPS of high fee transactions.
  # and primarily confirms that high-fee traffic has predictably low latency, and execution pipeline doesn't get backed up.
  run-forge-realistic-env-graceful-workload-sweep:
    if: ${{ github.event_name != 'pull_request' && always() }}
    needs: [determine-test-metadata, run-forge-realistic-env-graceful-overload] # Only run after the previous job completes
    uses: aptos-labs/aptos-core/.github/workflows/workflow-run-forge.yaml@main
    secrets: inherit
    with:
      IMAGE_TAG: ${{ needs.determine-test-metadata.outputs.IMAGE_TAG }}
      FORGE_NAMESPACE: forge-realistic-env-graceful-workload-sweep-${{ needs.determine-test-metadata.outputs.BRANCH_HASH }}
      FORGE_RUNNER_DURATION_SECS: 2100 # Run for 5 minutes per test, 7 tests.
      FORGE_TEST_SUITE: realistic_env_graceful_workload_sweep
      POST_TO_SLACK: true

  # Test varies workload, which is user-contracts, such that max throughput varies from high to mid to low, 
  # while testing that unrelated transactions paying the same gas price, are able to go through.
  run-forge-realistic-env-fairness-workload-sweep:
    if: ${{ github.event_name != 'pull_request' && always() }}
    needs: [determine-test-metadata, run-forge-realistic-env-graceful-workload-sweep] # Only run after the previous job completes
    uses: aptos-labs/aptos-core/.github/workflows/workflow-run-forge.yaml@main
    secrets: inherit
    with:
      IMAGE_TAG: ${{ needs.determine-test-metadata.outputs.IMAGE_TAG }}
      FORGE_NAMESPACE: forge-realistic-env-fairness-workload-sweep-${{ needs.determine-test-metadata.outputs.BRANCH_HASH }}
      FORGE_RUNNER_DURATION_SECS: 900 # Run for 5 minutes per test, 3 tests.
      FORGE_TEST_SUITE: realistic_env_fairness_workload_sweep
      POST_TO_SLACK: true

  # Test which tunes all configurations for largest throughput possible (potentially sacrificing latency a bit)
  run-forge-realistic-network-tuned-for-throughput:
    if: ${{ github.event_name != 'pull_request' && always() }}
    needs: [ determine-test-metadata, run-forge-realistic-env-fairness-workload-sweep ] # Only run after the previous job completes
    uses: aptos-labs/aptos-core/.github/workflows/workflow-run-forge.yaml@main
    secrets: inherit
    with:
      IMAGE_TAG: ${{ needs.determine-test-metadata.outputs.IMAGE_TAG }}
      FORGE_NAMESPACE: forge-realistic-network-tuned-for-throughput-${{ needs.determine-test-metadata.outputs.BRANCH_HASH }}
      FORGE_RUNNER_DURATION_SECS: 900 # Run for 15 minutes
      FORGE_TEST_SUITE: realistic_network_tuned_for_throughput
      FORGE_ENABLE_PERFORMANCE: true
      POST_TO_SLACK: true

  ### Forge Correctness/Componenet/Stress tests

  # Run small-ish load, but checks that at all times all nodes are making progress, 
  # catching any unexpected unreliabilities/delays in consensus
  run-forge-consensus-stress-test:
    if: ${{ github.event_name != 'pull_request' && always() }}
    needs: [determine-test-metadata, run-forge-realistic-network-tuned-for-throughput] # Only run after the previous job completes
    uses: aptos-labs/aptos-core/.github/workflows/workflow-run-forge.yaml@main
    secrets: inherit
    with:
      IMAGE_TAG: ${{ needs.determine-test-metadata.outputs.IMAGE_TAG }}
      FORGE_NAMESPACE: forge-consensus-stress-test-${{ needs.determine-test-metadata.outputs.BRANCH_HASH }}
      FORGE_RUNNER_DURATION_SECS: 2400 # Run for 40 minutes
      FORGE_TEST_SUITE: consensus_stress_test
      POST_TO_SLACK: true

  # Send a mix of different workloads, to catch issues with different interactions of workloads.
  # this is MUCH MUCH less comprehensive than replay-verify, but the best we can do with txn emitter at the moment
  run-forge-workload-mix-test:
    if: ${{ github.event_name != 'pull_request' && always() }}
    needs: [determine-test-metadata, run-forge-consensus-stress-test] # Only run after the previous job completes
    uses: aptos-labs/aptos-core/.github/workflows/workflow-run-forge.yaml@main
    secrets: inherit
    with:
      IMAGE_TAG: ${{ needs.determine-test-metadata.outputs.IMAGE_TAG }}
      FORGE_NAMESPACE: forge-workload-mix-test-${{ needs.determine-test-metadata.outputs.BRANCH_HASH }}
      FORGE_RUNNER_DURATION_SECS: 900 # Run for 15 minutes
      FORGE_TEST_SUITE: workload_mix
      POST_TO_SLACK: true

  run-forge-single-vfn-perf:
    if: ${{ github.event_name != 'pull_request' && always() }}
    needs: [determine-test-metadata, run-forge-workload-mix-test] # Only run after the previous job completes
    uses: aptos-labs/aptos-core/.github/workflows/workflow-run-forge.yaml@main
    secrets: inherit
    with:
      IMAGE_TAG: ${{ needs.determine-test-metadata.outputs.IMAGE_TAG }}
      FORGE_NAMESPACE: forge-continuous-e2e-single-vfn-${{ needs.determine-test-metadata.outputs.BRANCH_HASH }}
      FORGE_RUNNER_DURATION_SECS: 480 # Run for 8 minutes
      FORGE_TEST_SUITE: single_vfn_perf
      POST_TO_SLACK: true

  run-forge-fullnode-reboot-stress-test:
    if: ${{ github.event_name != 'pull_request' && always() }}
    needs: [determine-test-metadata, run-forge-single-vfn-perf] # Only run after the previous job completes
    uses: aptos-labs/aptos-core/.github/workflows/workflow-run-forge.yaml@main
    secrets: inherit
    with:
      IMAGE_TAG: ${{ needs.determine-test-metadata.outputs.IMAGE_TAG }}
      FORGE_NAMESPACE: forge-fullnode-reboot-stress-${{ needs.determine-test-metadata.outputs.BRANCH_HASH }}
      FORGE_RUNNER_DURATION_SECS: 1800 # Run for 30 minutes
      FORGE_TEST_SUITE: fullnode_reboot_stress_test
      POST_TO_SLACK: true

  ### Compatibility Forge tests

  run-forge-compat:
    if: ${{ github.event_name != 'pull_request' && always() }}
    needs: [determine-test-metadata, run-forge-fullnode-reboot-stress-test] # Only run after the previous job completes
    uses: aptos-labs/aptos-core/.github/workflows/workflow-run-forge.yaml@main
    secrets: inherit
    with:
      FORGE_NAMESPACE: forge-compat-${{ needs.determine-test-metadata.outputs.BRANCH_HASH }}
      FORGE_RUNNER_DURATION_SECS: 300 # Run for 5 minutes
      # This will upgrade from testnet branch to the latest main
      FORGE_TEST_SUITE: compat
      IMAGE_TAG: ${{ needs.determine-test-metadata.outputs.IMAGE_TAG_FOR_COMPAT_TEST }}
      GIT_SHA: ${{ needs.determine-test-metadata.outputs.IMAGE_TAG }} # this is the git ref to checkout
      POST_TO_SLACK: true

  ### Changing working quorum Forge tests

  # Send low TPS (100 TPS)
  # Cut network on enough nodes, such that all others are needed for consensus. Then bring a few back, and cut 
  # same amount of new ones - requiring all that were brought back to state-sync and continue executing.
  # Check that in each iteration - we were able to make meaningful progress.
  run-forge-changing-working-quorum-test:
    if: ${{ github.event_name != 'pull_request' && always() }}
    needs: [determine-test-metadata, run-forge-compat] # Only run after the previous job completes
    uses: aptos-labs/aptos-core/.github/workflows/workflow-run-forge.yaml@main
    secrets: inherit
    with:
      IMAGE_TAG: ${{ needs.determine-test-metadata.outputs.IMAGE_TAG }}
      FORGE_NAMESPACE: forge-changing-working-quorum-test-${{ needs.determine-test-metadata.outputs.BRANCH_HASH }}
      FORGE_RUNNER_DURATION_SECS: 1200 # Run for 20 minutes
      FORGE_TEST_SUITE: changing_working_quorum_test
      POST_TO_SLACK: true
      FORGE_ENABLE_FAILPOINTS: true

  # Same as above run-forge-changing-working-quorum-test, just sending a bit higher load - 500TPS
  # TODO - we should probably increase load here significantly
  run-forge-changing-working-quorum-test-high-load:
    if: ${{ github.event_name != 'pull_request' && always() }}
    needs: [determine-test-metadata, run-forge-changing-working-quorum-test] # Only run after the previous job completes
    uses: aptos-labs/aptos-core/.github/workflows/workflow-run-forge.yaml@main
    secrets: inherit
    with:
      IMAGE_TAG: ${{ needs.determine-test-metadata.outputs.IMAGE_TAG }}
      FORGE_NAMESPACE: forge-changing-working-quorum-test-high-load-${{ needs.determine-test-metadata.outputs.BRANCH_HASH }}
      FORGE_RUNNER_DURATION_SECS: 900 # Run for 15 minutes
      FORGE_TEST_SUITE: changing_working_quorum_test_high_load
      POST_TO_SLACK: true
      FORGE_ENABLE_FAILPOINTS: true

  # Measures PFN latencies with a constant TPS (with a realistic environment)
  run-forge-pfn-const-tps-realistic-env:
    if: ${{ github.event_name != 'pull_request' && always() }}
    needs: [determine-test-metadata, run-forge-changing-working-quorum-test-high-load] # Only run after the previous job completes
    uses: aptos-labs/aptos-core/.github/workflows/workflow-run-forge.yaml@main
    secrets: inherit
    with:
      IMAGE_TAG: ${{ needs.determine-test-metadata.outputs.IMAGE_TAG }}
      FORGE_NAMESPACE: forge-pfn-const-tps-with-realistic-env-${{ needs.determine-test-metadata.outputs.BRANCH_HASH }}
      FORGE_RUNNER_DURATION_SECS: 900 # Run for 15 minutes
      FORGE_TEST_SUITE: pfn_const_tps_with_realistic_env
      POST_TO_SLACK: true


  # longest test for last, to get useful signal from short tests first

  # Run a production config (same as land blocking run) max load (via mempool backlog), but run it for 2 hours,
  # to check reliability and consistency of the newtork. 
  run-forge-realistic-env-max-load-long:
    if: ${{ github.event_name != 'pull_request' && always() }}
    needs: [determine-test-metadata, run-forge-pfn-const-tps-realistic-env] # Only run after the previous job completes
    uses: aptos-labs/aptos-core/.github/workflows/workflow-run-forge.yaml@main
    secrets: inherit
    with:
      IMAGE_TAG: ${{ needs.determine-test-metadata.outputs.IMAGE_TAG }}
      FORGE_NAMESPACE: forge-realistic-env-max-load-long-${{ needs.determine-test-metadata.outputs.BRANCH_HASH }}
      FORGE_RUNNER_DURATION_SECS: 7200 # Run for 2 hours
      FORGE_TEST_SUITE: realistic_env_max_load_large
      POST_TO_SLACK: true
